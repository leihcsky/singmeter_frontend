/**
 * éŸ³é«˜æ£€æµ‹å·¥å…·ç±»
 * ä½¿ç”¨ Web Audio API å’Œ pitchy åº“è¿›è¡Œå®æ—¶éŸ³é«˜æ£€æµ‹
 */

import { PitchDetector } from 'pitchy';

// éŸ³ç¬¦é¢‘ç‡æ˜ å°„è¡¨ (A4 = 440Hz)
const NOTE_NAMES = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];

/**
 * å°†é¢‘ç‡è½¬æ¢ä¸ºéŸ³ç¬¦åç§°
 * @param {number} frequency - é¢‘ç‡ (Hz)
 * @returns {object} { note: éŸ³ç¬¦å, octave: å…«åº¦, cents: éŸ³åˆ†åç§» }
 */
export function frequencyToNote(frequency) {
  if (!frequency || frequency < 20) {
    return { note: '', octave: 0, cents: 0, fullNote: '' };
  }

  const noteNum = 12 * (Math.log(frequency / 440) / Math.log(2));
  const noteIndex = Math.round(noteNum) + 69; // MIDI note number
  const cents = Math.floor((noteNum - Math.round(noteNum)) * 100);
  
  const octave = Math.floor(noteIndex / 12) - 1;
  const note = NOTE_NAMES[noteIndex % 12];
  const fullNote = `${note}${octave}`;

  return { note, octave, cents, fullNote };
}

/**
 * è·å–å£°éƒ¨ç±»å‹
 * @param {string} lowestNote - æœ€ä½éŸ³
 * @param {string} highestNote - æœ€é«˜éŸ³
 * @returns {string} å£°éƒ¨ç±»å‹
 */
export function getVoiceType(lowestNote, highestNote) {
  // ç®€åŒ–çš„å£°éƒ¨åˆ¤æ–­é€»è¾‘
  const noteToMidi = (noteStr) => {
    const match = noteStr.match(/([A-G]#?)(\d+)/);
    if (!match) return 0;
    const [, note, octave] = match;
    const noteIndex = NOTE_NAMES.indexOf(note);
    return (parseInt(octave) + 1) * 12 + noteIndex;
  };

  const lowestMidi = noteToMidi(lowestNote);
  const highestMidi = noteToMidi(highestNote);
  const avgMidi = (lowestMidi + highestMidi) / 2;

  // æ ¹æ®å¹³å‡éŸ³é«˜åˆ¤æ–­å£°éƒ¨
  if (avgMidi < 55) return 'Bass'; // ç”·ä½éŸ³
  if (avgMidi < 62) return 'Baritone'; // ç”·ä¸­éŸ³
  if (avgMidi < 67) return 'Tenor'; // ç”·é«˜éŸ³
  if (avgMidi < 72) return 'Alto'; // å¥³ä½éŸ³
  if (avgMidi < 77) return 'Mezzo-Soprano'; // å¥³ä¸­éŸ³
  return 'Soprano'; // å¥³é«˜éŸ³
}

/**
 * éŸ³é«˜æ£€æµ‹å™¨ç±»
 */
export class AudioPitchDetector {
  constructor() {
    this.audioContext = null;
    this.analyser = null;
    this.microphone = null;
    this.detector = null;
    this.buffer = null;
    this.isRunning = false;
  }

  /**
   * åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡å’Œéº¦å…‹é£
   */
  async initialize() {
    try {
      console.log('ğŸ¤ Starting microphone initialization...');

      // Check if getUserMedia is supported
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        console.error('âŒ getUserMedia is not supported in this browser');

        // Try legacy API
        const getUserMedia = navigator.getUserMedia ||
                           navigator.webkitGetUserMedia ||
                           navigator.mozGetUserMedia ||
                           navigator.msGetUserMedia;

        if (!getUserMedia) {
          throw new Error('getUserMedia is not supported in this browser');
        }

        console.log('âš ï¸ Using legacy getUserMedia API');

        // Use legacy API with Promise wrapper
        return new Promise((resolve, reject) => {
          getUserMedia.call(navigator, { audio: true },
            (stream) => {
              this.initializeAudioContext(stream);
              resolve({ success: true });
            },
            (error) => {
              console.error('âŒ Legacy getUserMedia failed:', error);
              reject(error);
            }
          );
        });
      }

      console.log('âœ… getUserMedia is supported');
      console.log('ğŸ”’ Current protocol:', window.location.protocol);
      console.log('ğŸŒ Current host:', window.location.host);

      // Check if we're on HTTPS or localhost
      const isSecureContext = window.isSecureContext;
      console.log('ğŸ” Is secure context:', isSecureContext);

      // Detect mobile browser
      const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
      console.log('ğŸ“± Is mobile browser:', isMobile);

      if (!isSecureContext && window.location.protocol !== 'http:') {
        console.warn('âš ï¸ Not in secure context, getUserMedia may fail');
        // On mobile, this is critical - throw a clear error
        if (isMobile) {
          throw new Error('Microphone access requires HTTPS. Please access this site via a secure connection (https://).');
        }
      }

      // For mobile browsers, use minimal constraints for better compatibility
      // Some mobile browsers have issues with detailed audio constraints
      console.log('ğŸ“± Requesting microphone access...');
      let stream;

      if (isMobile) {
        // Mobile browsers: use minimal constraints
        console.log('ğŸ“± Using minimal constraints for mobile compatibility');
        try {
          stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          console.log('âœ… Got microphone stream on mobile');
        } catch (mobileError) {
          console.error('âŒ Mobile getUserMedia failed:', mobileError);
          // Provide more helpful error message for mobile
          if (mobileError.name === 'NotAllowedError' || mobileError.name === 'PermissionDeniedError') {
            throw new Error('Microphone permission denied. Please allow microphone access in your browser settings and try again.');
          }
          throw mobileError;
        }
      } else {
        // Desktop: try simple first, then detailed
        try {
          stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          console.log('âœ… Got microphone stream with simple constraints');
        } catch (simpleError) {
          console.warn('âš ï¸ Simple constraints failed, trying with detailed constraints:', simpleError);

          // Try with detailed constraints
          try {
            stream = await navigator.mediaDevices.getUserMedia({
              audio: {
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: false
              }
            });
            console.log('âœ… Got microphone stream with detailed constraints');
          } catch (detailedError) {
            console.error('âŒ Detailed constraints also failed:', detailedError);
            throw simpleError; // Throw the original error
          }
        }
      }

      // Initialize audio context
      this.initializeAudioContext(stream);

      console.log('âœ… Microphone initialization complete');
      return { success: true };

    } catch (error) {
      console.error('âŒ Microphone initialization failed:', error);
      console.error('Error name:', error.name);
      console.error('Error message:', error.message);
      console.error('Error stack:', error.stack);

      // è¿”å›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
      return {
        success: false,
        error: error.message,
        errorName: error.name, // NotAllowedError, NotFoundError, etc.
        errorType: this.getErrorType(error)
      };
    }
  }

  /**
   * åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
   */
  initializeAudioContext(stream) {
    console.log('ğŸµ Initializing audio context...');

    // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
    console.log('âœ… Audio context created, sample rate:', this.audioContext.sampleRate);

    // åˆ›å»ºéŸ³é¢‘æº
    this.microphone = this.audioContext.createMediaStreamSource(stream);
    console.log('âœ… Media stream source created');

    // åˆ›å»ºåˆ†æå™¨
    this.analyser = this.audioContext.createAnalyser();
    this.analyser.fftSize = 2048;
    this.microphone.connect(this.analyser);
    console.log('âœ… Analyser created and connected');

    // åˆ›å»ºéŸ³é«˜æ£€æµ‹å™¨
    this.detector = PitchDetector.forFloat32Array(this.analyser.fftSize);
    this.buffer = new Float32Array(this.analyser.fftSize);
    console.log('âœ… Pitch detector created');
  }

  /**
   * è·å–é”™è¯¯ç±»å‹
   */
  getErrorType(error) {
    if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
      return 'permission_denied';
    } else if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
      return 'no_device';
    } else if (error.name === 'NotReadableError' || error.name === 'TrackStartError') {
      return 'device_in_use';
    } else if (error.name === 'OverconstrainedError' || error.name === 'ConstraintNotSatisfiedError') {
      return 'constraints_error';
    } else if (error.name === 'TypeError') {
      return 'type_error';
    } else if (error.name === 'SecurityError') {
      return 'security_error';
    } else {
      return 'unknown_error';
    }
  }

  /**
   * å¼€å§‹æ£€æµ‹éŸ³é«˜
   * @param {function} callback - å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶æ£€æµ‹åˆ°çš„é¢‘ç‡
   */
  startDetection(callback) {
    if (!this.analyser || !this.detector) {
      console.error('è¯·å…ˆåˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡');
      return;
    }

    // å¦‚æœå·²ç»åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢
    if (this.isRunning) {
      console.warn('âš ï¸ Detection already running, stopping first...');
      this.stopDetection();
    }

    this.isRunning = true;
    console.log('âœ… Started pitch detection');

    // äººå£°é¢‘ç‡èŒƒå›´ï¼š
    // æ ‡å‡†èŒƒå›´ï¼šE2 (82 Hz) - C6 (1046 Hz)
    // ä¸ºäº†å®‰å…¨è¿‡æ»¤å™ªéŸ³ï¼Œæˆ‘ä»¬æ‰©å±•åˆ° C2 (65 Hz) - E6 (1318 Hz)
    // è¿™æ ·å¯ä»¥æ•æ‰åˆ°æå°‘æ•° Basso Profundo çš„è¶…ä½éŸ³
    const MIN_HUMAN_FREQUENCY = 65;   // C2 (extended range for noise filtering)
    const MAX_HUMAN_FREQUENCY = 1318; // E6 (extended range for noise filtering)

    const detect = () => {
      if (!this.isRunning) return;

      // è·å–éŸ³é¢‘æ•°æ®
      this.analyser.getFloatTimeDomainData(this.buffer);

      // æ£€æµ‹éŸ³é«˜
      const [pitch, clarity] = this.detector.findPitch(this.buffer, this.audioContext.sampleRate);

      // è®¡ç®—éŸ³é‡ï¼ˆRMS - Root Mean Squareï¼‰
      let sum = 0;
      for (let i = 0; i < this.buffer.length; i++) {
        sum += this.buffer[i] * this.buffer[i];
      }
      const rms = Math.sqrt(sum / this.buffer.length);
      const volume = rms * 100; // è½¬æ¢ä¸º 0-100 çš„èŒƒå›´

      // è¿‡æ»¤æ¡ä»¶ï¼š
      // 1. é¢‘ç‡ä¸ºæ­£æ•°ä¸”åœ¨äººå£°èŒƒå›´å†…
      // 2. æ¸…æ™°åº¦è¦æ±‚ï¼ˆåŠ¨æ€è°ƒæ•´ï¼‰ï¼š
      //    - æä½éŸ³ï¼ˆ< 150 Hzï¼‰ï¼šclarity > 0.75ï¼ˆå¾ˆå®½æ¾ï¼Œå› ä¸ºæä½éŸ³å¾ˆéš¾æ£€æµ‹ï¼‰
      //    - ä½éŸ³ï¼ˆ150-300 Hzï¼‰ï¼šclarity > 0.80ï¼ˆå®½æ¾ï¼Œå› ä¸ºä½éŸ³æ¸…æ™°åº¦è¾ƒä½ï¼‰
      //    - ä¸­éŸ³ï¼ˆ300-500 Hzï¼‰ï¼šclarity > 0.85ï¼ˆé€‚ä¸­ï¼‰
      //    - é«˜éŸ³ï¼ˆ>= 500 Hzï¼‰ï¼šclarity > 0.85ï¼ˆé€‚ä¸­ï¼Œé«˜éŸ³é€šå¸¸æ¸…æ™°åº¦ä¹Ÿä¸é«˜ï¼‰
      // 3. éŸ³é‡è¶³å¤Ÿï¼ˆ> 0.3ï¼Œç¡®ä¿ç”¨æˆ·åœ¨å‘å£°ï¼Œè¿‡æ»¤æå°çš„å™ªéŸ³ï¼‰
      let clarityThreshold;
      if (pitch < 150) {
        clarityThreshold = 0.75; // æä½éŸ³
      } else if (pitch < 300) {
        clarityThreshold = 0.80; // ä½éŸ³
      } else {
        clarityThreshold = 0.85; // ä¸­é«˜éŸ³
      }

      // è°ƒè¯•ï¼šæ¯ç§’è¾“å‡ºä¸€æ¬¡æ£€æµ‹çŠ¶æ€
      const now = Date.now();
      if (!this.lastDebugTime || now - this.lastDebugTime > 1000) {
        this.lastDebugTime = now;
        console.log(`ğŸµ Pitch: ${pitch?.toFixed(1) || 'null'} Hz, Clarity: ${clarity.toFixed(2)}, Volume: ${volume.toFixed(2)}, Threshold: ${clarityThreshold}`);
      }

      if (pitch > 0 &&
          pitch >= MIN_HUMAN_FREQUENCY &&
          pitch <= MAX_HUMAN_FREQUENCY &&
          clarity > clarityThreshold &&
          volume > 0.3) {
        callback(pitch, clarity);
      } else {
        callback(null, clarity);
      }

      // ç»§ç»­æ£€æµ‹
      requestAnimationFrame(detect);
    };

    detect();
  }

  /**
   * åœæ­¢æ£€æµ‹
   */
  stopDetection() {
    if (this.isRunning) {
      console.log('â¹ï¸ Stopped pitch detection');
    }
    this.isRunning = false;
  }

  /**
   * æ¸…ç†èµ„æº
   */
  cleanup() {
    this.stopDetection();
    
    if (this.microphone) {
      this.microphone.disconnect();
      this.microphone.mediaStream.getTracks().forEach(track => track.stop());
    }
    
    if (this.analyser) {
      this.analyser.disconnect();
    }
    
    if (this.audioContext) {
      this.audioContext.close();
    }

    this.audioContext = null;
    this.analyser = null;
    this.microphone = null;
    this.detector = null;
    this.buffer = null;
  }
}

